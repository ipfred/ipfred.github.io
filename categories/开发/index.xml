<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>开发 - 分类 | Fred的知识库</title>
    <link>https://ipfred.github.io/categories/%E5%BC%80%E5%8F%91/</link>
    <description>开发 - 分类 | Fred的知识库</description>
    <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>330446875@qq.com (Fred)</managingEditor>
      <webMaster>330446875@qq.com (Fred)</webMaster><copyright>本站内容采用 CC BY-NC-SA 4.0 国际许可协议。</copyright><lastBuildDate>Tue, 23 Apr 2024 20:01:01 &#43;0800</lastBuildDate><atom:link href="https://ipfred.github.io/categories/%E5%BC%80%E5%8F%91/" rel="self" type="application/rss+xml" /><item>
  <title>Hadoop概览</title>
  <link>https://ipfred.github.io/bigdata/hadoop/hadoop%E6%A6%82%E8%A7%88/</link>
  <pubDate>Tue, 23 Apr 2024 20:01:01 &#43;0800</pubDate>
  <author>Fred</author>
  <guid>https://ipfred.github.io/bigdata/hadoop/hadoop%E6%A6%82%E8%A7%88/</guid>
  <description><![CDATA[<h1 id="hdfs" class="heading-element">
  <a href="#hdfs" class="heading-mark"></a>HDFS</h1><ol>
<li>HDFS概述</li>
</ol>
<p>Hadoop 分布式系统框架中，首要的基础功能就是文件系统，在 Hadoop 中使用 FileSystem 这个抽象类来表示我们的文件系统，这个抽象类下面有很多子实现类，究竟使用哪一种，需要看我们具体的实现类，在我们实际工作中，用到的最多的就是HDFS(分布式文件系统)以及LocalFileSystem(本地文件系统)了。</p>
<p>在现代的企业环境中，单机容量往往无法存储大量数据，需要跨机器存储。统一管理分布在集群上的文件系统称为分布式文件系统。</p>
<p>HDFS（Hadoop  Distributed  File  System）是 Hadoop 项目的一个子项目。是 Hadoop 的核心组件之一，  Hadoop 非常适于存储大型数据 (比如 TB 和 PB)，其就是使用 HDFS 作为存储系统. HDFS 使用多台计算机存储文件，并且提供统一的访问接口，像是访问一个普通文件系统一样使用分布式文件系统。</p>
<p><a class="lightgallery" href="https://files.catbox.moe/6l0xa2.png?size=large" data-thumbnail="https://files.catbox.moe/6l0xa2.png?size=small" data-sub-html="<h2>6l0xa2.png</h2>"><img loading="lazy" src="https://files.catbox.moe/6l0xa2.png" alt="6l0xa2.png" srcset="https://files.catbox.moe/6l0xa2.png?size=small, https://files.catbox.moe/6l0xa2.png?size=medium 1.5x, https://files.catbox.moe/6l0xa2.png?size=large 2x" data-title="6l0xa2.png" style="background: url(/images/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}"/></a></p>
<ol start="2">
<li>HDFS架构</li>
</ol>
<p><a class="lightgallery" href="https://files.catbox.moe/7srz72.png?size=large" data-thumbnail="https://files.catbox.moe/7srz72.png?size=small" data-sub-html="<h2>7srz72.png</h2>"><img loading="lazy" src="https://files.catbox.moe/7srz72.png" alt="7srz72.png" srcset="https://files.catbox.moe/7srz72.png?size=small, https://files.catbox.moe/7srz72.png?size=medium 1.5x, https://files.catbox.moe/7srz72.png?size=large 2x" data-title="7srz72.png" style="background: url(/images/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}"/></a></p>
<p>HDFS是一个主/从（Mater/Slave）体系结构，由三部分组成： NameNode 和 DataNode 以及 SecondaryNamenode：</p>
<p>● NameNode 负责管理整个文件系统的元数据，以及每一个路径（文件）所对应的数据块信息。<br>
● DataNode 负责管理用户的文件数据块，每一个数据块都可以在多个 DataNode 上存储多个副本，默认为3个。<br>
● Secondary NameNode 用来监控 HDFS 状态的辅助后台程序，每隔一段时间获取 HDFS 元数据的快照。最主要作用是辅助 NameNode 管理元数据信息。</p>
<p><a class="lightgallery" href="https://files.catbox.moe/76lm4z.png?size=large" data-thumbnail="https://files.catbox.moe/76lm4z.png?size=small" data-sub-html="<h2>76lm4z.png</h2>"><img loading="lazy" src="https://files.catbox.moe/76lm4z.png" alt="76lm4z.png" srcset="https://files.catbox.moe/76lm4z.png?size=small, https://files.catbox.moe/76lm4z.png?size=medium 1.5x, https://files.catbox.moe/76lm4z.png?size=large 2x" data-title="76lm4z.png" style="background: url(/images/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}"/></a></p>
<ol start="3">
<li>HDFS的特性</li>
</ol>
<p>首先，它是一个文件系统，用于存储文件，通过统一的命名空间目录树来定位文件；</p>
<p>其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色。</p>
<ol>
<li>master/slave 架构（主从架构）</li>
</ol>
<p>HDFS 采用 master/slave 架构。一般一个 HDFS 集群是有一个 Namenode 和一定数目的 Datanode 组成。Namenode 是 HDFS 集群主节点，Datanode 是 HDFS 集群从节点，两种角色各司其职，共同协调完成分布式的文件存储服务。</p>
<ol start="2">
<li>分块存储(Block)</li>
</ol>
<p>HDFS 中的文件在物理上是分块存储（block）的，块的大小可以通过配置参数来规定，默认大小在 hadoop2.x 版本中是 128M。</p>
<ol start="3">
<li>名字空间（NameSpace）</li>
</ol>
<p>HDFS 支持传统的层次型文件组织结构。用户或者应用程序可以创建目录，然后将文件保存在这些目录里。文件系统名字空间的层次结构和大多数现有的文件系统类似：用户可以创建、删除、移动或重命名文件。 Namenode 负责维护文件系统的名字空间，任何对文件系统名字空间或属性的修改都将被 Namenode 记录下来。 HDFS 会给客户端提供一个统一的抽象目录树，客户端通过路径来访问文件，形如：hdfs://namenode:port/dir-a/dir-b/dir-c/file.data。</p>
<ol start="4">
<li>NameNode 元数据管理</li>
</ol>
<p>我们把目录结构及文件分块位置信息叫做元数据。NameNode 负责维护整个 HDFS 文件系统的目录树结构，以及每一个文件所对应的 block 块信息（block 的 id，及所在的 DataNode 服务器）。</p>
<ol start="5">
<li>DataNode 数据存储</li>
</ol>
<p>文件的各个 block 的具体存储管理由 DataNode 节点承担。每一个 block 都可以在多个 DataNode 上。DataNode 需要定时向 NameNode 汇报自己持有的 block 信息。 存储多个副本（副本数量也可以通过参数设置 dfs.replication，默认是 3）</p>
<ol start="6">
<li>副本机制</li>
</ol>
<p>为了容错，文件的所有 block 都会有副本。每个文件的 block 大小和副本系数都是可配置的。应用程序可以指定某个文件的副本数目。副本系数可以在文件创建的时候指定，也可以在之后改变。</p>
<ol start="7">
<li>一次写入，多次读出</li>
</ol>
<p>HDFS 是设计成适应一次写入，多次读出的场景，且不支持文件的修改。 正因为如此，HDFS 适合用来做大数据分析的底层存储服务，并不适合用来做网盘等应用，因为修改不方便，延迟大，网络开销大，成本太高。</p>
]]></description>
</item>
<item>
  <title>spark简单介绍</title>
  <link>https://ipfred.github.io/bigdata/spark/spark%E5%85%A5%E9%97%A8/</link>
  <pubDate>Sat, 20 Apr 2024 20:14:22 &#43;0800</pubDate>
  <author>Fred</author>
  <guid>https://ipfred.github.io/bigdata/spark/spark%E5%85%A5%E9%97%A8/</guid>
  <description><![CDATA[<p><a href="https://spark.apache.org/docs/2.4.8/configuration.html#available-properties"target="_blank" rel="external nofollow noopener noreferrer">Configuration - Spark 2.4.8 配置参数<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<p><a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/index.html"target="_blank" rel="external nofollow noopener noreferrer">Spark SQL — PySpark官方API手册<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<h2 id="apache-spark" class="heading-element">
  <a href="#apache-spark" class="heading-mark"></a>Apache Spark</h2><ul>
<li>A Unified engine for large-scale data analytics
Apache Spark is a unified analytics engine for large-scale data processing. It provides high-level APIs in Java, Scala, Python and R, and an optimized engine that supports general execution graphs. It also supports a rich set of higher-level tools including Spark SQL for SQL and structured data processing, pandas API on Spark for pandas workloads, MLlib for machine learning, GraphX for graph processing, and Structured Streaming for incremental computation and stream processing.</li>
</ul>
<h2 id="downloading" class="heading-element">
  <a href="#downloading" class="heading-mark"></a>Downloading</h2><p>Get Spark from the downloads page of the project website. This documentation is for Spark version 3.5.1. Spark uses Hadoop’s client libraries for HDFS and YARN. Downloads are pre-packaged for a handful of popular Hadoop versions. Users can also download a “Hadoop free” binary and run Spark with any Hadoop version by augmenting Spark’s classpath. Scala and Java users can include Spark in their projects using its Maven coordinates and Python users can install Spark from PyPI.</p>
<p>If you’d like to build Spark from source, visit Building Spark.</p>
]]></description>
</item>
<item>
  <title>python</title>
  <link>https://ipfred.github.io/lang/python/</link>
  <pubDate>Mon, 20 Feb 2023 20:14:22 &#43;0800</pubDate>
  <author>Fred</author>
  <guid>https://ipfred.github.io/lang/python/</guid>
  <description><![CDATA[<h2 id="python" class="heading-element">
  <a href="#python" class="heading-mark"></a>Python</h2><p>python第一篇文章扽扽</p>
<h2 id="标题二" class="heading-element">
  <a href="#%e6%a0%87%e9%a2%98%e4%ba%8c" class="heading-mark"></a>标题二</h2><h2 id="标题三" class="heading-element">
  <a href="#%e6%a0%87%e9%a2%98%e4%b8%89" class="heading-mark"></a>标题三</h2>]]></description>
</item>
<item>
  <title>python第二篇文章</title>
  <link>https://ipfred.github.io/lang/python/first/</link>
  <pubDate>Mon, 20 Feb 2023 20:14:22 &#43;0800</pubDate>
  <author>Fred</author>
  <guid>https://ipfred.github.io/lang/python/first/</guid>
  <description><![CDATA[<h2 id="python" class="heading-element">
  <a href="#python" class="heading-mark"></a>1 Python</h2><p>python第二篇文章扽扽</p>
<h2 id="标题二" class="heading-element">
  <a href="#%e6%a0%87%e9%a2%98%e4%ba%8c" class="heading-mark"></a>2 标题二</h2><h2 id="标题三" class="heading-element">
  <a href="#%e6%a0%87%e9%a2%98%e4%b8%89" class="heading-mark"></a>3 标题三</h2>]]></description>
</item>
<item>
  <title>python第一篇文章</title>
  <link>https://ipfred.github.io/lang/python/second/</link>
  <pubDate>Mon, 20 Feb 2023 20:14:22 &#43;0800</pubDate>
  <author>Fred</author>
  <guid>https://ipfred.github.io/lang/python/second/</guid>
  <description><![CDATA[<h2 id="python" class="heading-element">
  <a href="#python" class="heading-mark"></a>1 Python</h2><p>python第一篇文章扽扽</p>
<h2 id="标题二" class="heading-element">
  <a href="#%e6%a0%87%e9%a2%98%e4%ba%8c" class="heading-mark"></a>2 标题二</h2><h2 id="标题三" class="heading-element">
  <a href="#%e6%a0%87%e9%a2%98%e4%b8%89" class="heading-mark"></a>3 标题三</h2>]]></description>
</item>
<item>
  <title>我的第一篇文章</title>
  <link>https://ipfred.github.io/posts/first_post/</link>
  <pubDate>Mon, 20 Feb 2023 20:14:22 &#43;0800</pubDate>
  <author>Fred</author>
  <guid>https://ipfred.github.io/posts/first_post/</guid>
  <description><![CDATA[<h2 id="常用数据库的读写方式" class="heading-element">
  <a href="#%e5%b8%b8%e7%94%a8%e6%95%b0%e6%8d%ae%e5%ba%93%e7%9a%84%e8%af%bb%e5%86%99%e6%96%b9%e5%bc%8f" class="heading-mark"></a>1 常用数据库的读写方式</h2><p>A blog (a truncation of &ldquo;weblog&rdquo;) is an informational website published on the World Wide Web consisting of discrete, often informal diary-style text entries (posts). Posts are typically displayed in reverse chronological order so that the most recent post appears first, at the top of the web page. Until 2009, blogs were usually the work of a single individual,[citation needed] occasionally of a small group, and often covered a single subject or topic. In the 2010s, &ldquo;multi-author blogs&rdquo; (MABs) emerged, featuring the writing of multiple authors and sometimes professionally edited. MABs from newspapers, other media outlets, universities, think tanks, advocacy groups, and similar institutions account for an increasing quantity of blog traffic. The rise of Twitter and other &ldquo;microblogging&rdquo; systems helps integrate MABs and single-author blogs into the news media. Blog can also be used as a verb, meaning to maintain or add content to a blog.</p>
<h2 id="标题二" class="heading-element">
  <a href="#%e6%a0%87%e9%a2%98%e4%ba%8c" class="heading-mark"></a>2 标题二</h2><h2 id="标题三" class="heading-element">
  <a href="#%e6%a0%87%e9%a2%98%e4%b8%89" class="heading-mark"></a>3 标题三</h2>]]></description>
</item>
</channel>
</rss>
