<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>作品集 - 分类 | Fred的知识库</title>
    <link>https://ipfred.github.io/categories/project/</link>
    <description>作品集 - 分类 | Fred的知识库</description>
    <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>330446875@qq.com (Fred)</managingEditor>
      <webMaster>330446875@qq.com (Fred)</webMaster><copyright>本站内容采用 CC BY-NC-SA 4.0 国际许可协议。</copyright><atom:link href="https://ipfred.github.io/categories/project/" rel="self" type="application/rss+xml" /><item>
  <title>hadoop命令行的使用</title>
  <link>https://ipfred.github.io/bigdata/hadoop/hadoop%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%9A%84%E4%BD%BF%E7%94%A8/</link>
  <pubDate>Tue, 23 Apr 2024 22:01:01 &#43;0800</pubDate>
  <author>Fred</author>
  <guid>https://ipfred.github.io/bigdata/hadoop/hadoop%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%9A%84%E4%BD%BF%E7%94%A8/</guid>
  <description><![CDATA[<h2 id="hdfs-的命令行使用" class="heading-element">
  <a href="#hdfs-%e7%9a%84%e5%91%bd%e4%bb%a4%e8%a1%8c%e4%bd%bf%e7%94%a8" class="heading-mark"></a>1 HDFS 的命令行使用</h2><p><a href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/FileSystemShell.html"target="_blank" rel="external nofollow noopener noreferrer">Hadoop 命令行官方doc<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<p><code>hadoop fs</code>: 使用面最广，可以操作任务文件系统，包括本地文件系统、HDFS、FTP、S3等
<code>hdfs dfs</code>: 只能操作HDFS文件系统。</p>
<div class="highlight" id="id-1"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl"><span class="c1"># 下面两种效果是一样的</span>
</span></span><span class="line"><span class="cl">hdfs dfs -ls /user/hive
</span></span><span class="line"><span class="cl">hadoop fs -ls /user/hive/</span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>如果操作HDFS文件系统，推荐使用 hdfs dfs,如果需要操作其他系统文件，使用hadoop fs命令</p>
</blockquote>
<ul>
<li>help</li>
</ul>
<div class="highlight" id="id-2"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">格式:  hdfs dfs -help 操作命令
</span></span><span class="line"><span class="cl">作用: 查看某一个操作命令的参数信息</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>ls</li>
</ul>
<div class="highlight" id="id-3"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">格式：hdfs dfs -ls  URI
</span></span><span class="line"><span class="cl">作用：类似于Linux的ls命令，显示文件列表</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>lsr</li>
</ul>
<div class="highlight" id="id-4"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">格式  :   hdfs  dfs -lsr URI
</span></span><span class="line"><span class="cl">作用  : 在整个目录下递归执行ls, 与UNIX中的ls-R类似</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>mkdir</li>
</ul>
<div class="highlight" id="id-5"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">格式 ： hdfs  dfs  -mkdir <span class="o">[</span>-p<span class="o">]</span> &lt;paths&gt;
</span></span><span class="line"><span class="cl">作用 :   以&lt;paths&gt;中的URI作为参数，创建目录。使用-p参数可以递归创建目录</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>put</li>
</ul>
<div class="highlight" id="id-6"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">格式   ： hdfs dfs -put &lt;localsrc &gt;  ... &lt;dst&gt;
</span></span><span class="line"><span class="cl">作用 ：  将单个的源文件src或者多个源文件srcs从本地文件系统拷贝到目标文件系统中（&lt;dst&gt;对应的路径）。也可以从标准输入中读取输入，写入目标文件系统中
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">hdfs dfs -put  /rooot/bigdata.txt  /dir1</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>moveFromLocal</li>
</ul>
<div class="highlight" id="id-7"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">格式： hdfs  dfs -moveFromLocal  &lt;localsrc&gt;   &lt;dst&gt;
</span></span><span class="line"><span class="cl">作用:  和put命令类似，但是源文件localsrc拷贝之后自身被删除
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">hdfs  dfs -moveFromLocal  /root/bigdata.txt  /</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>copyFromLocal</li>
</ul>
<div class="highlight" id="id-8"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">格式:  hdfs dfs -copyFromLocal &lt;localsrc&gt; ... &lt;dst&gt;
</span></span><span class="line"><span class="cl">作用: 从本地文件系统中拷贝文件到hdfs路径去</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>appendToFile</li>
</ul>
<div class="highlight" id="id-9"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">格式: hdfs dfs -appendToFile &lt;localsrc&gt; ... &lt;dst&gt;
</span></span><span class="line"><span class="cl">作用: 追加一个或者多个文件到hdfs指定文件中.也可以从命令行读取输入.
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"> hdfs dfs -appendToFile  a.xml b.xml  /big.xml</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>moveToLocal</li>
</ul>
<div class="highlight" id="id-10"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">在 hadoop 2.6.4 版本测试还未未实现此方法
</span></span><span class="line"><span class="cl">格式：hadoop  dfs  -moveToLocal <span class="o">[</span>-crc<span class="o">]</span> &lt;src&gt; &lt;dst&gt;
</span></span><span class="line"><span class="cl">作用：将本地文件剪切到 HDFS</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>get</li>
</ul>
<div class="highlight" id="id-11"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">格式   hdfs dfs  -get <span class="o">[</span>-ignorecrc <span class="o">]</span>  <span class="o">[</span>-crc<span class="o">]</span>  &lt;src&gt; &lt;localdst&gt;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">作用：将文件拷贝到本地文件系统。 CRC 校验失败的文件通过-ignorecrc选项拷贝。 文件和CRC校验可以通过-CRC选项拷贝
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">hdfs dfs  -get   /bigdata.txt  /export/servers</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>getmerge</li>
</ul>
<div class="highlight" id="id-12"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">格式: hdfs dfs -getmerge &lt;src&gt; &lt;localdst&gt;
</span></span><span class="line"><span class="cl">作用: 合并下载多个文件，比如hdfs的目录 /aaa/下有多个文件:log.1, log.2,log.3,...</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>copyToLocal</li>
</ul>
<div class="highlight" id="id-13"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">格式:  hdfs dfs -copyToLocal &lt;src&gt; ... &lt;localdst&gt;
</span></span><span class="line"><span class="cl">作用:  从hdfs拷贝到本地</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>mv</li>
</ul>
<div class="highlight" id="id-14"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">格式  ： hdfs  dfs -mv URI   &lt;dest&gt;
</span></span><span class="line"><span class="cl">作用： 将hdfs上的文件从原路径移动到目标路径（移动之后文件删除），该命令不能跨文件系统
</span></span><span class="line"><span class="cl">hdfs  dfs  -mv  /dir1/bigdata.txt   /dir2</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>rm</li>
</ul>
<div class="highlight" id="id-15"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">格式： hdfs dfs -rm <span class="o">[</span>-r<span class="o">]</span> 【-skipTrash】 URI 【URI 。。。】
</span></span><span class="line"><span class="cl">作用： 删除参数指定的文件，参数可以有多个。  此命令只删除文件和非空目录。
</span></span><span class="line"><span class="cl">如果指定-skipTrash选项，那么在回收站可用的情况下，该选项将跳过回收站而直接删除文件；
</span></span><span class="line"><span class="cl">否则，在回收站可用时，在HDFS Shell 中执行此命令，会将文件暂时放到回收站中。
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">hdfs  dfs  -rm  -r  /dir1</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>cp</li>
</ul>
<div class="highlight" id="id-16"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">格式: hdfs  dfs  -cp URI <span class="o">[</span>URI ...<span class="o">]</span> &lt;dest&gt;
</span></span><span class="line"><span class="cl">作用： 将文件拷贝到目标路径中。如果&lt;dest&gt;  为目录的话，可以将多个文件拷贝到该目录下。
</span></span><span class="line"><span class="cl">-f
</span></span><span class="line"><span class="cl">选项将覆盖目标，如果它已经存在。
</span></span><span class="line"><span class="cl">-p
</span></span><span class="line"><span class="cl">选项将保留文件属性（时间戳、所有权、许可、ACL、XAttr）。
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">hdfs dfs -cp /dir1/a.txt  /dir2/bigdata.txt</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>cat</li>
</ul>
<div class="highlight" id="id-17"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">hdfs dfs  -cat  URI <span class="o">[</span>uri  ...<span class="o">]</span>
</span></span><span class="line"><span class="cl">作用：将参数所指示的文件内容输出到stdout
</span></span><span class="line"><span class="cl">hdfs dfs  -cat /bigdata.txt</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>tail</li>
</ul>
<div class="highlight" id="id-18"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">格式: hdfs dfs -tail path
</span></span><span class="line"><span class="cl">作用: 显示一个文件的末尾</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>text</li>
</ul>
<div class="highlight" id="id-19"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">格式:hdfs dfs -text path
</span></span><span class="line"><span class="cl">作用: 以字符形式打印一个文件的内容</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>chmod</li>
</ul>
<div class="highlight" id="id-20"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">格式:hdfs  dfs  -chmod  <span class="o">[</span>-R<span class="o">]</span>  URI<span class="o">[</span>URI  ...<span class="o">]</span>
</span></span><span class="line"><span class="cl">作用：改变文件权限。如果使用  -R 选项，则对整个目录有效递归执行。使用这一命令的用户必须是文件的所属用户，或者超级用户。
</span></span><span class="line"><span class="cl">hdfs dfs -chmod -R <span class="m">777</span> /bigdata.txt</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>chown</li>
</ul>
<div class="highlight" id="id-21"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">格式:  hdfs  dfs  -chmod  <span class="o">[</span>-R<span class="o">]</span>  URI<span class="o">[</span>URI ...<span class="o">]</span>
</span></span><span class="line"><span class="cl">作用：  改变文件的所属用户和用户组。如果使用  -R 选项，则对整个目录有效递归执行。使用这一命令的用户必须是文件的所属用户，或者超级用户。
</span></span><span class="line"><span class="cl">hdfs  dfs  -chown  -R hadoop:hadoop  /bigdata.txt</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>df</li>
</ul>
<div class="highlight" id="id-22"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">格式: hdfs dfs  -df  -h  path
</span></span><span class="line"><span class="cl">作用: 统计文件系统的可用空间信息</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>du</li>
</ul>
<div class="highlight" id="id-23"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">格式: hdfs dfs -du -s -h path
</span></span><span class="line"><span class="cl">作用: 统计文件夹的大小信息</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>count</li>
</ul>
<div class="highlight" id="id-24"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">格式: hdfs dfs -count path
</span></span><span class="line"><span class="cl">作用: 统计一个指定目录下的文件节点数量</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>setrep</li>
<li>expunge (慎用)</li>
</ul>
<div class="highlight" id="id-25"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">格式:  hdfs dfs -setrep num filePath
</span></span><span class="line"><span class="cl">作用: 设置hdfs中文件的副本数量
</span></span><span class="line"><span class="cl">注意: 即使设置的超过了datanode的数量,副本的数量也最多只能和datanode的数量是一致的</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="hdfs的高级使用命令" class="heading-element">
  <a href="#hdfs%e7%9a%84%e9%ab%98%e7%ba%a7%e4%bd%bf%e7%94%a8%e5%91%bd%e4%bb%a4" class="heading-mark"></a>2 hdfs的高级使用命令</h2><h3 id="hdfs文件限额配置" class="heading-element">
  <a href="#hdfs%e6%96%87%e4%bb%b6%e9%99%90%e9%a2%9d%e9%85%8d%e7%bd%ae" class="heading-mark"></a>2.1 HDFS文件限额配置</h3><p>在多人共用HDFS的环境下，配置设置非常重要。特别是在 Hadoop 处理大量资料的环境，如果没有配额管理，很容易把所有的空间用完造成别人无法存取。HDFS 的配额设定是针对目录而不是针对账号，可以让每个账号仅操作某一个目录，然后对目录设置配置。</p>
<p>HDFS 文件的限额配置允许我们以文件个数，或者文件大小来限制我们在某个目录下上传的文件数量或者文件内容总量，以便达到我们类似百度网盘网盘等限制每个用户允许上传的最大的文件的量。</p>
<div class="highlight" id="id-26"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl"> hdfs dfs -count -q -h /user/root/dir1  <span class="c1">#查看配额信息</span></span></span></code></pre></td></tr></table>
</div>
</div><h4 id="数量限额" class="heading-element">
  <a href="#%e6%95%b0%e9%87%8f%e9%99%90%e9%a2%9d" class="heading-mark"></a>2.1.1 数量限额</h4><div class="highlight" id="id-27"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">hdfs dfs  -mkdir -p /user/root/dir    <span class="c1">#创建hdfs文件夹</span>
</span></span><span class="line"><span class="cl">hdfs dfsadmin -setQuota <span class="m">2</span>  dir      <span class="c1"># 给该文件夹下面设置最多上传两个文件，发现只能上传一个文件</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">hdfs dfsadmin -clrQuota /user/root/dir  <span class="c1"># 清除文件数量限制</span>
</span></span><span class="line"><span class="cl">  </span></span></code></pre></td></tr></table>
</div>
</div><h4 id="空间大小限额" class="heading-element">
  <a href="#%e7%a9%ba%e9%97%b4%e5%a4%a7%e5%b0%8f%e9%99%90%e9%a2%9d" class="heading-mark"></a>2.1.2 空间大小限额</h4><p>在设置空间配额时，设置的空间至少是 block_size * 3 大小</p>
<div class="highlight" id="id-28"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">hdfs dfsadmin -setSpaceQuota 4k /user/root/dir   <span class="c1"># 限制空间大小4KB</span>
</span></span><span class="line"><span class="cl">hdfs dfs -put  /root/a.txt  /user/root/dir
</span></span><span class="line"><span class="cl"><span class="c1"># 生成任意大小的文件</span>
</span></span><span class="line"><span class="cl">dd <span class="k">if</span><span class="o">=</span>/dev/zero <span class="nv">of</span><span class="o">=</span>1.txt  <span class="nv">bs</span><span class="o">=</span>1M <span class="nv">count</span><span class="o">=</span><span class="m">2</span>     <span class="c1">#生成2M的文件</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 清除空间配额限制</span>
</span></span><span class="line"><span class="cl">hdfs dfsadmin -clrSpaceQuota /user/root/dir</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="hdfs-的安全模式" class="heading-element">
  <a href="#hdfs-%e7%9a%84%e5%ae%89%e5%85%a8%e6%a8%a1%e5%bc%8f" class="heading-mark"></a>2.2 HDFS 的安全模式</h3><p>安全模式是hadoop的一种保护机制，用于保证集群中的数据块的安全性。当集群启动的时候，会首先进入安全模式。当系统处于安全模式时会检查数据块的完整性。</p>
<p>假设我们设置的副本数（即参数dfs.replication）是3，那么在datanode上就应该有3个副本存在，假设只存在2个副本，那么比例就是2/3=0.666。hdfs默认的副本率0.999。我们的副本率0.666明显小于0.999，因此系统会自动的复制副本到其他dataNode，使得副本率不小于0.999。如果系统中有5个副本，超过我们设定的3个副本，那么系统也会删除多于的2个副本。</p>
<p>在安全模式状态下，文件系统只接受读数据请求，而不接受删除、修改等变更请求。在，当整个系统达到安全标准时，HDFS自动离开安全模式。30s</p>
<p>安全模式操作命令</p>
<div class="highlight" id="id-29"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">hdfs  dfsadmin  -safemode  get <span class="c1">#查看安全模式状态</span>
</span></span><span class="line"><span class="cl">hdfs  dfsadmin  -safemode  enter <span class="c1">#进入安全模式</span>
</span></span><span class="line"><span class="cl">hdfs  dfsadmin  -safemode  leave <span class="c1">#离开安全模式</span></span></span></code></pre></td></tr></table>
</div>
</div>]]></description>
</item>
</channel>
</rss>
