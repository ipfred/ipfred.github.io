# spark简单介绍

[Configuration - Spark 2.4.8 配置参数](https://spark.apache.org/docs/2.4.8/configuration.html#available-properties)

[Spark SQL — PySpark官方API手册](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/index.html)
## Apache Spark
- A Unified engine for large-scale data analytics
Apache Spark is a unified analytics engine for large-scale data processing. It provides high-level APIs in Java, Scala, Python and R, and an optimized engine that supports general execution graphs. It also supports a rich set of higher-level tools including Spark SQL for SQL and structured data processing, pandas API on Spark for pandas workloads, MLlib for machine learning, GraphX for graph processing, and Structured Streaming for incremental computation and stream processing.
## Downloading
Get Spark from the downloads page of the project website. This documentation is for Spark version 3.5.1. Spark uses Hadoop’s client libraries for HDFS and YARN. Downloads are pre-packaged for a handful of popular Hadoop versions. Users can also download a “Hadoop free” binary and run Spark with any Hadoop version by augmenting Spark’s classpath. Scala and Java users can include Spark in their projects using its Maven coordinates and Python users can install Spark from PyPI.

If you’d like to build Spark from source, visit Building Spark.

---

> 作者:   
> URL: http://localhost:1313/bigdata/spark/spark%E5%85%A5%E9%97%A8/  

